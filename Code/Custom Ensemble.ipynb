{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a64217c-c200-4bd8-95c4-d82c57d21cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten, InputLayer, Input, Dropout, Concatenate, GRU\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9520b069-da62-40e2-a444-87799e3204df",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = {\n",
    "    \"filtered\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_clean_labeled_train.csv\")\n",
    "    \n",
    "}\n",
    "datasets_test = {\n",
    "    \"filtered\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_clean_labeled_test.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da6e3-383a-4d06-a6d6-c732fa13ba0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6135af-2a84-4581-bd9a-ab695bdcbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(value):\n",
    "    return np.array([1, 0]) if value == 0 else np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb299f63-0d5a-4c72-abe3-34b4ca9d08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df):\n",
    "    X_train = df[[\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]].to_numpy()\n",
    "    y = df[\"class\"].to_numpy()\n",
    "    y = y.reshape(-1, 1)\n",
    "    \n",
    "    return X_train, y\n",
    "    \n",
    "def get_some(df,dataset_name):\n",
    "    datasets_name = [\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]\n",
    "    selected = []\n",
    "    for name in datasets_name:\n",
    "        if name != dataset_name:\n",
    "            selected.append(name)\n",
    "            \n",
    "    selected_dataset = df[(df[\"source\"] != dataset_name) & (df[\"source\"].notnull())]\n",
    "    X_train = selected_dataset[selected].to_numpy()\n",
    "    y = selected_dataset[\"class\"].to_numpy()\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    return X_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5a2967-b1c8-405a-bf5a-329b8d8027a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(array, threshold):\n",
    "    if array[1] > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe92e8a6-308c-4521-9827-d5b9667e1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tfidf(df):\n",
    "    \n",
    "    # Initialize the TF-IDF Vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Fit and transform the \"text\" column\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['text'])\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a DataFrame\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "    tfidf_tensor = torch.tensor(tfidf_matrix.toarray(), dtype=torch.float32)\n",
    "    return tfidf_tensor, tfidf_vectorizer\n",
    "    \n",
    "def get_some_tfidf(df, dataset_name):\n",
    "    datasets_name = [\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]\n",
    "    selected = []\n",
    "    for name in datasets_name:\n",
    "        if name != dataset_name:\n",
    "            selected.append(name)\n",
    "            \n",
    "    selected_dataset = df[(df[\"source\"] != dataset_name) & (df[\"source\"].notnull())]\n",
    "    \n",
    "    # Initialize the TF-IDF Vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Fit and transform the \"text\" column\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(selected_dataset['text'])\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a DataFrame\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "    tfidf_tensor = torch.tensor(tfidf_matrix.toarray(), dtype=torch.float32)\n",
    "    return tfidf_tensor, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c8fe30-25c3-45f7-b9e9-efc7b6631754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "\n",
    "            \n",
    "    X_train = df[[\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]].to_numpy()\n",
    "    y = df[\"class\"].to_numpy()\n",
    "    y = y.reshape(-1, 1)\n",
    "    return X_train, y\n",
    "\n",
    "# Gets all ensemble features from the selected dataset except for the provided dataset\n",
    "def get_some_features(df, dataset_name):\n",
    "    datasets_name = [\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]\n",
    "    selected = []\n",
    "    for name in datasets_name:\n",
    "        if name != dataset_name:\n",
    "            selected.append(name)\n",
    "    \n",
    "    X_train = df[selected].to_numpy()\n",
    "    y = df[\"class\"].to_numpy()\n",
    "    y = y.reshape(-1, 1)\n",
    "    return X_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be4998e-2046-4bbc-8236-6fd41322c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c7728b-e1e7-4bb2-9ba3-ee8b8a01886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleFeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 5000)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(500, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529b5d4c-4eba-41c6-9b46-a0feef2662f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12842, 5])\n",
      "torch.Size([12842, 43829])\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"davidson\"\n",
    "all_option = 1 # 1 = All datasets, all features, 2 = All datasets, missing 1 feature. 3 = all but 1 dataset, missing 1 feature\n",
    "option = 0 # 0 = ALL, 1 = only 1, 4 feature, 2 = all features 1 dataset,3 = 4 feature all but 1 dataset\n",
    "\n",
    "if all_option == 1:\n",
    "    tfidf_tensor, tfidf_vectorizer = get_all_tfidf(datasets_train[\"filtered\"])\n",
    "    X_train, y_train = get_all(datasets_train[\"filtered\"])\n",
    "elif all_option == 2:\n",
    "    tfidf_tensor, tfidf_vectorizer = get_some_tfidf(datasets_train[\"filtered\"], dataset_name)\n",
    "    X_train, y_train = get_some(datasets_train[\"filtered\"], dataset_name)\n",
    "else:\n",
    "    tfidf_tensor, tfidf_vectorizer = get_some_tfidf(datasets_train[\"filtered\"][datasets_train[\"filtered\"][\"source\"] != dataset_name], dataset_name)\n",
    "    X_train, y_train = get_some(datasets_train[\"filtered\"], dataset_name)\n",
    "\n",
    "if option == 0:\n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(datasets_test[\"filtered\"][\"text\"])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_all(datasets_test[\"filtered\"])\n",
    "elif option == 1:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] == dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_some_features(target_df,dataset_name)\n",
    "elif option == 3:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] != dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_some_features(target_df,dataset_name)\n",
    "else:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] == dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_features(target_df)\n",
    "\n",
    "\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "X_val = X_val.type(torch.float)\n",
    "y_val = y_val.type(torch.float)\n",
    "output_size = X_val.shape[1]\n",
    "print(X_val.shape)\n",
    "print(val_tfidf_tensor.shape)\n",
    "# Concat tfidf from text\n",
    "X_val = torch.cat((val_tfidf_tensor, X_val), dim=1)\n",
    "\n",
    "# Create a DataLoader\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a259aa3-7ae5-463e-a02d-26dd161c372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/100], Loss: 0.7468, Val Loss: 0.7165\n",
      "Epoch [2/100], Loss: 0.6869, Val Loss: 0.7098\n",
      "Epoch [3/100], Loss: 0.7088, Val Loss: 0.6956\n",
      "Epoch [4/100], Loss: 0.7051, Val Loss: 0.6929\n",
      "Epoch [5/100], Loss: 0.6602, Val Loss: 0.6919\n",
      "Epoch [6/100], Loss: 0.7201, Val Loss: 0.6917\n",
      "Epoch [7/100], Loss: 0.7057, Val Loss: 0.6900\n",
      "Epoch [8/100], Loss: 0.6930, Val Loss: 0.6877\n",
      "Epoch [9/100], Loss: 0.6632, Val Loss: 0.6837\n",
      "Epoch [10/100], Loss: 0.6702, Val Loss: 0.6808\n",
      "Epoch [11/100], Loss: 0.6762, Val Loss: 0.6802\n",
      "Epoch [12/100], Loss: 0.6765, Val Loss: 0.6803\n",
      "Epoch [13/100], Loss: 0.6981, Val Loss: 0.6806\n",
      "Epoch [14/100], Loss: 0.7365, Val Loss: 0.6808\n",
      "Epoch [15/100], Loss: 0.6664, Val Loss: 0.6805\n",
      "Epoch [16/100], Loss: 0.6855, Val Loss: 0.6818\n",
      "Epoch [17/100], Loss: 0.6358, Val Loss: 0.6804\n",
      "Epoch [18/100], Loss: 0.6971, Val Loss: 0.6816\n",
      "Epoch [19/100], Loss: 0.7216, Val Loss: 0.6824\n",
      "Epoch [20/100], Loss: 0.6875, Val Loss: 0.6830\n",
      "Epoch [21/100], Loss: 0.6833, Val Loss: 0.6825\n",
      "Early stopping at epoch 21\n",
      "Loaded best model state from epoch with lowest validation loss.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "n = tfidf_tensor.shape[1]\n",
    "patience = 10\n",
    "\n",
    "\n",
    "# Get ensemble data\n",
    "X_train, y_train = torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "X_train = X_train.type(torch.float)\n",
    "y_train = y_train.type(torch.float)\n",
    "output_size = X_train.shape[1]\n",
    "\n",
    "# Concat tfidf from text\n",
    "X_train = torch.cat((tfidf_tensor, X_train), dim=1)\n",
    "\n",
    "# Create a DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2048, shuffle=True)\n",
    "# val_loader = train_loader\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = SimpleFeedForwardNN(n, output_size)\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # For regression. Use nn.CrossEntropyLoss() for classification.\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        tfidf_input = inputs[:, :n]\n",
    "        extra_input = inputs[:, n:]\n",
    "        \n",
    "        outputs = model(tfidf_input)\n",
    "        ensemble_output = torch.sum(outputs * extra_input, dim=1, keepdim=True)\n",
    "\n",
    "        loss = criterion(ensemble_output, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            tfidf_input = inputs[:, :n]\n",
    "            extra_input = inputs[:, n:]\n",
    "            \n",
    "            outputs = model(tfidf_input)\n",
    "            ensemble_output = torch.sum(outputs * extra_input, dim=1, keepdim=True)\n",
    "            \n",
    "            loss = criterion(ensemble_output, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        best_model_state = model.state_dict()  # Save the best model state\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "# Load the best model state (if early stopping was triggered)\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print('Loaded best model state from epoch with lowest validation loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78681290-03fb-4f5d-a90a-43f7459926f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Hate Class: 0.7954545454545454\n",
      "Recall for Hate Class: 0.7388888888888889\n",
      "F1 Macro 0.849152053716737\n",
      "F1 Weighted 0.8934697038660049\n",
      "0.8 / 0.74 / 0.85 / 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93      2961\n",
      "         1.0       0.80      0.74      0.77       900\n",
      "\n",
      "    accuracy                           0.89      3861\n",
      "   macro avg       0.86      0.84      0.85      3861\n",
      "weighted avg       0.89      0.89      0.89      3861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"qian\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "option = 2 # 0 = ALL, 1 = only 1, 4 feature, 2 = all features 1 dataset,3 = 4 feature all but 1 dataset\n",
    "\n",
    "if option == 0:\n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(datasets_test[\"filtered\"])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_all(datasets_test[\"filtered\"])\n",
    "elif option == 1:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] == dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_some_features(target_df,dataset_name)\n",
    "elif option == 3:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] != dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_some_features(target_df,dataset_name)\n",
    "else:\n",
    "    target_df = datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] == dataset_name]\n",
    "    # target_df = target_df.dropna(subset=['text'])\n",
    "    # target_df = target_df[target_df['text'] != '']\n",
    "    \n",
    "    val_tfidf_tensor = tfidf_vectorizer.transform(target_df['text'])\n",
    "    val_tfidf_tensor = torch.tensor(val_tfidf_tensor.toarray(), dtype=torch.float32)\n",
    "    X_val, y_val = get_features(target_df)\n",
    "\n",
    "\n",
    "X_val, y_val = torch.from_numpy(X_val), torch.from_numpy(y_val)\n",
    "X_val = X_val.type(torch.float)\n",
    "y_val = y_val.type(torch.float)\n",
    "output_size = X_val.shape[1]\n",
    "\n",
    "# Concat tfidf from text\n",
    "X_val = torch.cat((val_tfidf_tensor, X_val), dim=1)\n",
    "\n",
    "# Create a DataLoader\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:  # Use your validation/test loader here\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        tfidf_input = inputs[:, :n]\n",
    "        extra_input = inputs[:, n:]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tfidf_input)\n",
    "        ensemble_output = torch.sum(outputs * extra_input, dim=1, keepdim=True)\n",
    "\n",
    "        # Convert probabilities to predicted class (0 or 1)\n",
    "        predicted = (ensemble_output > 0.5).float()\n",
    "        y_true.extend(targets.tolist())\n",
    "        y_pred.extend(predicted.tolist())\n",
    "\n",
    "y_val = y_true\n",
    "\n",
    "precision = precision_score(y_val, y_pred, average='binary')\n",
    "recall = recall_score(y_val, y_pred, average='binary')\n",
    "f1_macro_score = f1_score(y_val, y_pred, average='macro')\n",
    "f1_weighted_score = f1_score(y_val, y_pred, average='weighted')\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Precision for Hate Class:\", precision)\n",
    "print(\"Recall for Hate Class:\", recall)\n",
    "print(\"F1 Macro\", f1_macro_score)\n",
    "print(\"F1 Weighted\", f1_weighted_score)\n",
    "print(round(precision,2), \"/\",round(recall,2), \"/\", round(f1_macro_score,2), \"/\", round(f1_weighted_score,2))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cf84a5e-710d-441c-994e-4a464f00a37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jigsaw'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b8fd1f4-9b12-4189-9ac7-f84d98a24261",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"datasets\\model_training\\ensemble\\combined_filtered_train.csv\")\n",
    "test_df.to_csv(\"datasets\\model_training\\ensemble\\combined_filtered_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ae200bd-0655-4954-bdbc-798e596e75fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>davidson</th>\n",
       "      <th>hateval</th>\n",
       "      <th>ethos</th>\n",
       "      <th>jigsaw</th>\n",
       "      <th>qian</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21015</th>\n",
       "      <td>0</td>\n",
       "      <td>Been seeing the video a lot and it s just exce...</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>0</td>\n",
       "      <td>If they can t win to control it they want it d...</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.949048</td>\n",
       "      <td>0.066492</td>\n",
       "      <td>0.231610</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21017</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do companies hate people who want to give ...</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.575365</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21018</th>\n",
       "      <td>0</td>\n",
       "      <td>Even psychologists are like fuck that</td>\n",
       "      <td>0.013859</td>\n",
       "      <td>0.161847</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21019</th>\n",
       "      <td>0</td>\n",
       "      <td>you do realize bullets have to land somewhere ...</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>0</td>\n",
       "      <td>Treasury Dept Official Leaked Trump Associates...</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>0</td>\n",
       "      <td>Shep Smith Fanning the Flames 2423 via</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>0</td>\n",
       "      <td>I think they should be going after like you sa...</td>\n",
       "      <td>0.326074</td>\n",
       "      <td>0.446462</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>0</td>\n",
       "      <td>These are the people who think they re going t...</td>\n",
       "      <td>0.692558</td>\n",
       "      <td>0.986265</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.694234</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23471</th>\n",
       "      <td>0</td>\n",
       "      <td>Broward County Election witch Hold my non gmo ...</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.240437</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1809 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                               text  davidson  \\\n",
       "21015      0  Been seeing the video a lot and it s just exce...  0.003238   \n",
       "21016      0  If they can t win to control it they want it d...  0.010647   \n",
       "21017      0  Why do companies hate people who want to give ...  0.052604   \n",
       "21018      0              Even psychologists are like fuck that  0.013859   \n",
       "21019      0  you do realize bullets have to land somewhere ...  0.003990   \n",
       "...      ...                                                ...       ...   \n",
       "23467      0  Treasury Dept Official Leaked Trump Associates...  0.001599   \n",
       "23468      0             Shep Smith Fanning the Flames 2423 via  0.001721   \n",
       "23469      0  I think they should be going after like you sa...  0.326074   \n",
       "23470      0  These are the people who think they re going t...  0.692558   \n",
       "23471      0  Broward County Election witch Hold my non gmo ...  0.002823   \n",
       "\n",
       "        hateval     ethos    jigsaw      qian source  \n",
       "21015  0.032303  0.001687  0.000595  0.001298   None  \n",
       "21016  0.949048  0.066492  0.231610  0.001391   None  \n",
       "21017  0.575365  0.021553  0.001060  0.001223   None  \n",
       "21018  0.161847  0.062706  0.065887  0.001808   None  \n",
       "21019  0.007488  0.000253  0.000681  0.001224   None  \n",
       "...         ...       ...       ...       ...    ...  \n",
       "23467  0.005591  0.001130  0.000624  0.001304   None  \n",
       "23468  0.017017  0.006173  0.000609  0.001272   None  \n",
       "23469  0.446462  0.023663  0.007875  0.001610   None  \n",
       "23470  0.986265  0.015629  0.694234  0.001611   None  \n",
       "23471  0.005664  0.004245  0.240437  0.002984   None  \n",
       "\n",
       "[1809 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"source\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd69b363-6dfb-4e01-831d-7a5979374f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>davidson</th>\n",
       "      <th>hateval</th>\n",
       "      <th>ethos</th>\n",
       "      <th>jigsaw</th>\n",
       "      <th>qian</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>I am the real vampire nigger</td>\n",
       "      <td>0.873000</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.995353</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>613</td>\n",
       "      <td>0</td>\n",
       "      <td>Check your slutty fat girl friends instagram p...</td>\n",
       "      <td>0.033234</td>\n",
       "      <td>0.989482</td>\n",
       "      <td>0.223525</td>\n",
       "      <td>0.995148</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "      <td>Instagram needs to stop being a bitch</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.978749</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>pussy whipped</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.762364</td>\n",
       "      <td>0.098111</td>\n",
       "      <td>0.855310</td>\n",
       "      <td>0.936555</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>616</td>\n",
       "      <td>0</td>\n",
       "      <td>bitch don t do this RT</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.965728</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>12518</td>\n",
       "      <td>1</td>\n",
       "      <td>On the flip a family member is getting into an...</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>0.862036</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.844060</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>12519</td>\n",
       "      <td>1</td>\n",
       "      <td>religion is gay loser</td>\n",
       "      <td>0.861051</td>\n",
       "      <td>0.074809</td>\n",
       "      <td>0.664744</td>\n",
       "      <td>0.994715</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>12520</td>\n",
       "      <td>1</td>\n",
       "      <td>If women want retarded kids let them The rest ...</td>\n",
       "      <td>0.885251</td>\n",
       "      <td>0.971841</td>\n",
       "      <td>0.090143</td>\n",
       "      <td>0.852065</td>\n",
       "      <td>0.997261</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>12661</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah I m retarded</td>\n",
       "      <td>0.122651</td>\n",
       "      <td>0.076663</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.996766</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>12662</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah he wasn t any of those things but he was ...</td>\n",
       "      <td>0.887542</td>\n",
       "      <td>0.455518</td>\n",
       "      <td>0.316338</td>\n",
       "      <td>0.078379</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>hateval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  class                                               text  \\\n",
       "115          612      0                       I am the real vampire nigger   \n",
       "116          613      0  Check your slutty fat girl friends instagram p...   \n",
       "117          614      0              Instagram needs to stop being a bitch   \n",
       "118          615      0                                      pussy whipped   \n",
       "119          616      0                             bitch don t do this RT   \n",
       "...          ...    ...                                                ...   \n",
       "3568       12518      1  On the flip a family member is getting into an...   \n",
       "3569       12519      1                              religion is gay loser   \n",
       "3570       12520      1  If women want retarded kids let them The rest ...   \n",
       "3652       12661      1                                  Yeah I m retarded   \n",
       "3653       12662      1  Yeah he wasn t any of those things but he was ...   \n",
       "\n",
       "      davidson   hateval     ethos    jigsaw      qian   source  \n",
       "115   0.873000  0.018652  0.004240  0.993853  0.995353  hateval  \n",
       "116   0.033234  0.989482  0.223525  0.995148  0.995851  hateval  \n",
       "117   0.001843  0.978749  0.005122  0.036563  0.003552  hateval  \n",
       "118   0.003237  0.762364  0.098111  0.855310  0.936555  hateval  \n",
       "119   0.014555  0.965728  0.000753  0.001563  0.001636  hateval  \n",
       "...        ...       ...       ...       ...       ...      ...  \n",
       "3568  0.007541  0.862036  0.000576  0.000611  0.844060  hateval  \n",
       "3569  0.861051  0.074809  0.664744  0.994715  0.004697  hateval  \n",
       "3570  0.885251  0.971841  0.090143  0.852065  0.997261  hateval  \n",
       "3652  0.122651  0.076663  0.010756  0.001251  0.996766  hateval  \n",
       "3653  0.887542  0.455518  0.316338  0.078379  0.934167  hateval  \n",
       "\n",
       "[800 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1acb287d-4bd2-480e-9737-16a08090a45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>davidson</th>\n",
       "      <th>hateval</th>\n",
       "      <th>ethos</th>\n",
       "      <th>jigsaw</th>\n",
       "      <th>qian</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lmao chill spook You think you Better than nig...</td>\n",
       "      <td>0.808160</td>\n",
       "      <td>0.360156</td>\n",
       "      <td>0.077775</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.994904</td>\n",
       "      <td>davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>chris brown is trash</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.910892</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Having sex with a guy wont keep him around for...</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.927659</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.990970</td>\n",
       "      <td>0.941269</td>\n",
       "      <td>davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>You see me shining on yo bitch ass</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.842289</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.089469</td>\n",
       "      <td>0.664199</td>\n",
       "      <td>davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Bum bitch won t even my type</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.980811</td>\n",
       "      <td>0.064114</td>\n",
       "      <td>0.169962</td>\n",
       "      <td>0.240064</td>\n",
       "      <td>davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28176</th>\n",
       "      <td>30094</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuck that nigger demon Yahweh Craw back up it ...</td>\n",
       "      <td>0.963582</td>\n",
       "      <td>0.045365</td>\n",
       "      <td>0.161895</td>\n",
       "      <td>0.996736</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28177</th>\n",
       "      <td>30095</td>\n",
       "      <td>1</td>\n",
       "      <td>brings up kike shill porn spaming throws kike ...</td>\n",
       "      <td>0.804230</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.260310</td>\n",
       "      <td>0.786530</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28178</th>\n",
       "      <td>30096</td>\n",
       "      <td>1</td>\n",
       "      <td>Hillary Klintoon lost to a half nigger for the...</td>\n",
       "      <td>0.751409</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>0.113964</td>\n",
       "      <td>0.964383</td>\n",
       "      <td>0.986766</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28179</th>\n",
       "      <td>30097</td>\n",
       "      <td>1</td>\n",
       "      <td>why would any bitch accuse a 9yo boy of sexual...</td>\n",
       "      <td>0.857041</td>\n",
       "      <td>0.853251</td>\n",
       "      <td>0.861583</td>\n",
       "      <td>0.990994</td>\n",
       "      <td>0.128043</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28180</th>\n",
       "      <td>30098</td>\n",
       "      <td>1</td>\n",
       "      <td>the left s new favorite N word is Nigger Nazi</td>\n",
       "      <td>0.112924</td>\n",
       "      <td>0.216663</td>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.979209</td>\n",
       "      <td>0.994838</td>\n",
       "      <td>qian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22915 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  class                                               text  \\\n",
       "0               0      0  Lmao chill spook You think you Better than nig...   \n",
       "1               1      0                               chris brown is trash   \n",
       "2               2      0  Having sex with a guy wont keep him around for...   \n",
       "3               3      0                 You see me shining on yo bitch ass   \n",
       "4               4      0                       Bum bitch won t even my type   \n",
       "...           ...    ...                                                ...   \n",
       "28176       30094      1  Fuck that nigger demon Yahweh Craw back up it ...   \n",
       "28177       30095      1  brings up kike shill porn spaming throws kike ...   \n",
       "28178       30096      1  Hillary Klintoon lost to a half nigger for the...   \n",
       "28179       30097      1  why would any bitch accuse a 9yo boy of sexual...   \n",
       "28180       30098      1      the left s new favorite N word is Nigger Nazi   \n",
       "\n",
       "       davidson   hateval     ethos    jigsaw      qian    source  \n",
       "0      0.808160  0.360156  0.077775  0.997260  0.994904  davidson  \n",
       "1      0.003686  0.040048  0.017826  0.910892  0.003160  davidson  \n",
       "2      0.002583  0.927659  0.012692  0.990970  0.941269  davidson  \n",
       "3      0.002031  0.842289  0.009289  0.089469  0.664199  davidson  \n",
       "4      0.001948  0.980811  0.064114  0.169962  0.240064  davidson  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "28176  0.963582  0.045365  0.161895  0.996736  0.997359      qian  \n",
       "28177  0.804230  0.070466  0.260310  0.786530  0.995143      qian  \n",
       "28178  0.751409  0.032321  0.113964  0.964383  0.986766      qian  \n",
       "28179  0.857041  0.853251  0.861583  0.990994  0.128043      qian  \n",
       "28180  0.112924  0.216663  0.020068  0.979209  0.994838      qian  \n",
       "\n",
       "[22915 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = datasets_train[\"filtered\"][datasets_train[\"filtered\"][\"source\"] != dataset_name]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77674adc-c968-4ee7-9b49-f605a4454462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df):\n",
    "    new_df = df.copy()\n",
    "    source = [None] * len(new_df)\n",
    "    for key in datasets_train:\n",
    "        if key != \"combined\":\n",
    "            merged_df = pd.merge(new_df, datasets_train[key], on='text', how='left', indicator=True)\n",
    "            source = [\n",
    "                key if _merge == 'both' else src\n",
    "                for _merge, src in zip(merged_df['_merge'], source)\n",
    "            ]\n",
    "    \n",
    "    new_df[\"source\"] = source\n",
    "    \n",
    "    new_df = new_df.dropna(subset=['text'])\n",
    "    \n",
    "    new_df = new_df[new_df['text'] != '']\n",
    "    return new_df\n",
    "\n",
    "train_df = process_df(datasets_train[\"combined\"])\n",
    "test_df = process_df(datasets_test[\"combined\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
