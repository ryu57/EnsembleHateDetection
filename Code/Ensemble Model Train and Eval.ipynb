{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aae5f40-d8ae-4c04-8d24-334ba920766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim.downloader as api\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, Conv1D, GlobalMaxPooling1D, MaxPooling1D, Flatten, InputLayer, Input, Dropout, Concatenate, GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa5ca6e-7b1e-4521-8574-2bf6455f447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = {\n",
    "    \"davidson\" : pd.read_csv(\"datasets\\model_training\\ensemble\\davidson_ensemble_train.csv\"),\n",
    "    \"hateval\" : pd.read_csv(\"datasets\\model_training\\ensemble\\hateval_ensemble_train.csv\"),\n",
    "    \"ethos\" : pd.read_csv(\"datasets\\model_training\\ensemble\\ethos_ensemble_train.csv\"),\n",
    "    \"jigsaw\": pd.read_csv(\"datasets\\model_training\\ensemble\\jigsaw_ensemble_train.csv\"),\n",
    "    \"qian\": pd.read_csv(\"datasets\\model_training\\ensemble\\qian_ensemble_train.csv\"),\n",
    "    \"combined\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_ensemble_train.csv\")\n",
    "}\n",
    "datasets_test = {\n",
    "    \"davidson\" : pd.read_csv(\"datasets\\model_training\\ensemble\\davidson_ensemble_test.csv\"),\n",
    "    \"hateval\" : pd.read_csv(\"datasets\\model_training\\ensemble\\hateval_ensemble_test.csv\"),\n",
    "    \"ethos\" : pd.read_csv(\"datasets\\model_training\\ensemble\\ethos_ensemble_test.csv\"),\n",
    "    \"jigsaw\": pd.read_csv(\"datasets\\model_training\\ensemble\\jigsaw_ensemble_test.csv\"),\n",
    "    \"qian\": pd.read_csv(\"datasets\\model_training\\ensemble\\qian_ensemble_test.csv\"),\n",
    "    \"combined\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_ensemble_test.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36546157-0d02-42c4-b2a9-98627f2eab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = datasets_train[\"combined\"].copy()\n",
    "source = [None] * len(new_df)\n",
    "for key in datasets_train:\n",
    "    if key != \"combined\":\n",
    "        merged_df = pd.merge(new_df, datasets_train[key], on='text', how='left', indicator=True)\n",
    "        source = [\n",
    "            key if _merge == 'both' else src\n",
    "            for _merge, src in zip(merged_df['_merge'], source)\n",
    "        ]\n",
    "\n",
    "new_df[\"source\"] = source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a61481-3be0-47b2-9adf-4cd43bf80b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ffc673-a12c-4395-8643-b11321e18c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28267\n"
     ]
    }
   ],
   "source": [
    "print(len(new_df[new_df[\"source\"] == \"qian\"]) + len(new_df[new_df[\"source\"] == \"hateval\"])  + len(new_df[new_df[\"source\"] == \"jigsaw\"])  + len(new_df[new_df[\"source\"] == \"davidson\"])  + len(new_df[new_df[\"source\"] == \"ethos\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05411b89-975e-4da3-bedf-da75198648b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>davidson</th>\n",
       "      <th>hateval</th>\n",
       "      <th>ethos</th>\n",
       "      <th>jigsaw</th>\n",
       "      <th>qian</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21015</th>\n",
       "      <td>0</td>\n",
       "      <td>Been seeing the video a lot and it s just exce...</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.032303</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>0</td>\n",
       "      <td>If they can t win to control it they want it d...</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.949048</td>\n",
       "      <td>0.066492</td>\n",
       "      <td>0.231610</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21017</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do companies hate people who want to give ...</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.575365</td>\n",
       "      <td>0.021553</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21018</th>\n",
       "      <td>0</td>\n",
       "      <td>Even psychologists are like fuck that</td>\n",
       "      <td>0.013859</td>\n",
       "      <td>0.161847</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.065887</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21019</th>\n",
       "      <td>0</td>\n",
       "      <td>you do realize bullets have to land somewhere ...</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>0</td>\n",
       "      <td>Treasury Dept Official Leaked Trump Associates...</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>0</td>\n",
       "      <td>Shep Smith Fanning the Flames 2423 via</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>0</td>\n",
       "      <td>I think they should be going after like you sa...</td>\n",
       "      <td>0.326074</td>\n",
       "      <td>0.446462</td>\n",
       "      <td>0.023663</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>0</td>\n",
       "      <td>These are the people who think they re going t...</td>\n",
       "      <td>0.692558</td>\n",
       "      <td>0.986265</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.694234</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23471</th>\n",
       "      <td>0</td>\n",
       "      <td>Broward County Election witch Hold my non gmo ...</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.240437</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1832 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                               text  davidson  \\\n",
       "21015      0  Been seeing the video a lot and it s just exce...  0.003238   \n",
       "21016      0  If they can t win to control it they want it d...  0.010647   \n",
       "21017      0  Why do companies hate people who want to give ...  0.052604   \n",
       "21018      0              Even psychologists are like fuck that  0.013859   \n",
       "21019      0  you do realize bullets have to land somewhere ...  0.003990   \n",
       "...      ...                                                ...       ...   \n",
       "23467      0  Treasury Dept Official Leaked Trump Associates...  0.001599   \n",
       "23468      0             Shep Smith Fanning the Flames 2423 via  0.001721   \n",
       "23469      0  I think they should be going after like you sa...  0.326074   \n",
       "23470      0  These are the people who think they re going t...  0.692558   \n",
       "23471      0  Broward County Election witch Hold my non gmo ...  0.002823   \n",
       "\n",
       "        hateval     ethos    jigsaw      qian source  \n",
       "21015  0.032303  0.001687  0.000595  0.001298   None  \n",
       "21016  0.949048  0.066492  0.231610  0.001391   None  \n",
       "21017  0.575365  0.021553  0.001060  0.001223   None  \n",
       "21018  0.161847  0.062706  0.065887  0.001808   None  \n",
       "21019  0.007488  0.000253  0.000681  0.001224   None  \n",
       "...         ...       ...       ...       ...    ...  \n",
       "23467  0.005591  0.001130  0.000624  0.001304   None  \n",
       "23468  0.017017  0.006173  0.000609  0.001272   None  \n",
       "23469  0.446462  0.023663  0.007875  0.001610   None  \n",
       "23470  0.986265  0.015629  0.694234  0.001611   None  \n",
       "23471  0.005664  0.004245  0.240437  0.002984   None  \n",
       "\n",
       "[1832 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[new_df[\"source\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5ca662-a374-42da-b48e-d170105ce4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(value):\n",
    "    return np.array([1, 0]) if value == 0 else np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6763a1-17b9-4316-b393-357b25183ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all():\n",
    "    X_train = datasets_train[\"combined\"][[\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]].to_numpy()\n",
    "    y = datasets_train[\"combined\"][\"class\"].to_numpy()\n",
    "    \n",
    "    y_train = np.zeros((y.size, 2))\n",
    "    y_train[np.arange(y.size), y] = 1\n",
    "    \n",
    "    X_val= datasets_test[\"combined\"][[\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]].to_numpy()\n",
    "    y = datasets_test[\"combined\"][\"class\"].to_numpy()\n",
    "    \n",
    "    y_val = np.zeros((y.size, 2))\n",
    "    y_val[np.arange(y.size), y] = 1\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "# Get all data except for the supplied dataset name as well as all ensemble features except for the supplied dataset name\n",
    "def get_some(dataset_name):\n",
    "    datasets_name = [\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]\n",
    "    selected = []\n",
    "    for name in datasets_name:\n",
    "        if name != dataset_name:\n",
    "            selected.append(name)\n",
    "            \n",
    "    selected_dataset = new_df[new_df[\"source\"] != dataset_name]\n",
    "\n",
    "    X_train = selected_dataset[selected].to_numpy()\n",
    "    y = selected_dataset[\"class\"].to_numpy()\n",
    "    \n",
    "    y_train = np.zeros((y.size, 2))\n",
    "    y_train[np.arange(y.size), y] = 1\n",
    "    \n",
    "    X_val= selected_dataset[selected].to_numpy()\n",
    "    y = selected_dataset[\"class\"].to_numpy()\n",
    "    \n",
    "    y_val = np.zeros((y.size, 2))\n",
    "    y_val[np.arange(y.size), y] = 1\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d3b10a-acff-4d55-b3ba-4585daef0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "\n",
    "            \n",
    "    X_train = df[[\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]].to_numpy()\n",
    "    y = df[\"class\"].to_numpy()\n",
    "    return X_train, y\n",
    "\n",
    "# Gets all ensemble features from the selected dataset except for the provided dataset\n",
    "def get_some_features(df, dataset_name):\n",
    "    datasets_name = [\"davidson\",\"hateval\",\"ethos\",\"jigsaw\",\"qian\"]\n",
    "    selected = []\n",
    "    for name in datasets_name:\n",
    "        if name != dataset_name:\n",
    "            selected.append(name)\n",
    "            \n",
    "    X_train = df[selected].to_numpy()\n",
    "    y = df[\"class\"].to_numpy()\n",
    "    return X_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d3ae98-ab62-4af2-8e0b-866425af57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(array, threshold):\n",
    "    if array[1] > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb63fca-ea4f-47bf-9989-8ef7b812f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ethos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85dd8d5d-52c9-4476-805a-b7c314455983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "236/236 [==============================] - 2s 5ms/step - loss: 0.6016 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.8194\n",
      "Epoch 2/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8232 - val_loss: 0.4244 - val_accuracy: 0.8167\n",
      "Epoch 3/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.3858 - accuracy: 0.8286 - val_loss: 0.4032 - val_accuracy: 0.8201\n",
      "Epoch 4/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8322 - val_loss: 0.3984 - val_accuracy: 0.8217\n",
      "Epoch 5/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.3530 - accuracy: 0.8349 - val_loss: 0.3994 - val_accuracy: 0.8218\n",
      "Epoch 6/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.3490 - accuracy: 0.8366 - val_loss: 0.4000 - val_accuracy: 0.8220\n",
      "Epoch 7/50\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.3467 - accuracy: 0.8369Restoring model weights from the end of the best epoch: 4.\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.3469 - accuracy: 0.8368 - val_loss: 0.4008 - val_accuracy: 0.8228\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d78b8b4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, y_train, X_val, y_val = get_all()\n",
    "X_train, y_train, X_val, y_val = get_some(dataset_name)\n",
    "\n",
    "meta_model_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(5,)),  # Change input shape based on the number of base models\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "\n",
    "meta_model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "meta_model_nn.fit(X_train, y_train, epochs=50, batch_size=128, validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3bbdab-b998-43a9-848b-99054c2ee691",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_nn.save_weights(f\"weights\\ensemble\\ensemble_meta.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6976df74-1dd0-46dc-856b-65f0e98df376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "Precision for Hate Class: 0.37735849056603776\n",
      "Recall for Hate Class: 0.40816326530612246\n",
      "F1 Macro 0.633578431372549\n",
      "F1 Weighted 0.7958718604498656\n",
      "0.38 / 0.41 / 0.63 / 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       250\n",
      "           1       0.38      0.41      0.39        49\n",
      "\n",
      "    accuracy                           0.79       299\n",
      "   macro avg       0.63      0.64      0.63       299\n",
      "weighted avg       0.80      0.79      0.80       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X, y_true = get_features(datasets_test[dataset_name])\n",
    "X, y_true = get_some_features(datasets_test[dataset_name], dataset_name)\n",
    "y_pred_2d = meta_model_nn.predict(X)\n",
    "\n",
    "y_pred = [threshold(array, 0.5) for array in y_pred_2d]\n",
    "# y_val = np.argmax(y_true, axis=1)\n",
    "y_val = y_true\n",
    "\n",
    "precision = precision_score(y_val, y_pred, average='binary')\n",
    "recall = recall_score(y_val, y_pred, average='binary')\n",
    "f1_macro_score = f1_score(y_val, y_pred, average='macro')\n",
    "f1_weighted_score = f1_score(y_val, y_pred, average='weighted')\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Precision for Hate Class:\", precision)\n",
    "print(\"Recall for Hate Class:\", recall)\n",
    "print(\"F1 Macro\", f1_macro_score)\n",
    "print(\"F1 Weighted\", f1_weighted_score)\n",
    "print(round(precision,2), \"/\",round(recall,2), \"/\", round(f1_macro_score,2), \"/\", round(f1_weighted_score,2))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b61a5d7-9444-4d51-854e-a110917f10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractXy(df):\n",
    "    X = df['text'].astype(\"str\").tolist()\n",
    "    X = np.array(X).reshape(len(X), 1)\n",
    "    y = pd.get_dummies(df['class']).values.astype(int)\n",
    "    return X, y\n",
    "\n",
    "def feature_rep(df):\n",
    "    tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3\"\n",
    "    tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3\"\n",
    "    \n",
    "    X = df['text'].astype(\"str\").tolist()\n",
    "    X = np.array(X).reshape(len(X), 1)\n",
    "    y = pd.get_dummies(df['class']).values.astype(int)\n",
    "    input_layer = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    \n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing', trainable=False)\n",
    "    encoder_inputs = preprocessing_layer(input_layer)\n",
    "    \n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=False, name='BERT_encoder')\n",
    "    feature_rep_end = encoder(encoder_inputs)['sequence_output']\n",
    "    \n",
    "    return input_layer,feature_rep_end, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f8bbd8-1082-45c9-bb5b-057bc52555fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU_Model: # Model from Zhang et al.\n",
    "    def __init__(self, input_layer, feature_rep_end):\n",
    "        self.input_layer = input_layer\n",
    "        self.feature_rep_end = feature_rep_end\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        conv_layer = Conv1D(filters=100, kernel_size=4, activation='relu')(self.feature_rep_end)\n",
    "        max_pool = MaxPooling1D(pool_size=4)(conv_layer)\n",
    "        gru = GRU(100, return_sequences=True)(max_pool)\n",
    "        global_pool = GlobalMaxPooling1D()(gru)\n",
    "        dense1 = Dense(2, activation='softmax',kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01))(global_pool)\n",
    "        model = Model(inputs=self.input_layer, outputs=dense1)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8931c628-380d-4a9f-b14b-9c525045f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(input_layer, feature_rep_end, X_train, y_train, X_val, y_val, batch_size=128, epochs=30, patience=3):\n",
    "    model_class = CNN_GRU_Model(input_layer, feature_rep_end)\n",
    "    model = model_class.build_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True, verbose=1)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping])\n",
    "    \n",
    "    # Evaluate the model on the training data\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_train, axis=1)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "\n",
    "    return model\n",
    "\n",
    "def eval(model, X_val, y_val):\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "    precision = precision_score(y_val, y_pred, average='binary')\n",
    "    recall = recall_score(y_val, y_pred, average='binary')\n",
    "    f1_macro_score = f1_score(y_val, y_pred, average='macro')\n",
    "    f1_weighted_score = f1_score(y_val, y_pred, average='weighted')\n",
    "    report = classification_report(y_val, y_pred)\n",
    "\n",
    "    print(\"Precision for Hate Class:\", precision)\n",
    "    print(\"Recall for Hate Class:\", recall)\n",
    "    print(\"F1 Macro\", f1_macro_score)\n",
    "    print(\"F1 Weighted\", f1_weighted_score)\n",
    "    print(round(precision,2), \"/\",round(recall,2), \"/\", round(f1_macro_score,2), \"/\", round(f1_weighted_score,2))\n",
    "    print(report)\n",
    "    return round(precision,2), round(recall,2), round(f1_macro_score,2), round(f1_weighted_score,2), report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e90e162-8d9c-4eb0-9738-69a036dae947",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = {\n",
    "    \"filtered\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_clean_labeled_train.csv\")\n",
    "    \n",
    "}\n",
    "datasets_test = {\n",
    "    \"filtered\": pd.read_csv(\"datasets\\model_training\\ensemble\\combined_clean_labeled_test.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e71fe9a-5b22-43ee-9397-1960787e9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"qian\"\n",
    "selected_dataset = datasets_train[\"filtered\"][datasets_train[\"filtered\"][\"source\"] != dataset_name]\n",
    "# selected_dataset = datasets_train[\"filtered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ebb76d-bb6e-473d-a52c-53a768422404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "164/164 [==============================] - 300s 2s/step - loss: 0.6152 - accuracy: 0.7988 - val_loss: 0.5100 - val_accuracy: 0.8095\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 290s 2s/step - loss: 0.4563 - accuracy: 0.8273 - val_loss: 0.4553 - val_accuracy: 0.8177\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 292s 2s/step - loss: 0.4223 - accuracy: 0.8435 - val_loss: 0.4411 - val_accuracy: 0.8306\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 292s 2s/step - loss: 0.3929 - accuracy: 0.8591 - val_loss: 0.4340 - val_accuracy: 0.8352\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 292s 2s/step - loss: 0.3645 - accuracy: 0.8773 - val_loss: 0.4454 - val_accuracy: 0.8320\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 291s 2s/step - loss: 0.3282 - accuracy: 0.8989 - val_loss: 0.4438 - val_accuracy: 0.8354\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.9277Restoring model weights from the end of the best epoch: 4.\n",
      "164/164 [==============================] - 294s 2s/step - loss: 0.2773 - accuracy: 0.9277 - val_loss: 0.4721 - val_accuracy: 0.8223\n",
      "Epoch 7: early stopping\n",
      "656/656 [==============================] - 155s 235ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93     16229\n",
      "           1       0.79      0.71      0.75      4739\n",
      "\n",
      "    accuracy                           0.89     20968\n",
      "   macro avg       0.85      0.83      0.84     20968\n",
      "weighted avg       0.89      0.89      0.89     20968\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_layer,feature_rep_end, X_train, y_train = feature_rep(selected_dataset)\n",
    "# X_val, y_val = extractXy(datasets_test[\"filtered\"])\n",
    "X_val, y_val = extractXy(datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] != dataset_name])\n",
    "model = train_eval_model(input_layer,feature_rep_end, X_train, y_train,X_val, y_val, batch_size=128, epochs=10, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76628b82-1915-4619-93e7-4434d698f233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 28s 237ms/step\n",
      "Precision for Hate Class: 0.6161290322580645\n",
      "Recall for Hate Class: 0.6366666666666667\n",
      "F1 Macro 0.7550699475810491\n",
      "F1 Weighted 0.8238449140589303\n",
      "0.62 / 0.64 / 0.76 / 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      2961\n",
      "           1       0.62      0.64      0.63       900\n",
      "\n",
      "    accuracy                           0.82      3861\n",
      "   macro avg       0.75      0.76      0.76      3861\n",
      "weighted avg       0.82      0.82      0.82      3861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = extractXy(datasets_test[\"filtered\"][datasets_test[\"filtered\"][\"source\"] == dataset_name])\n",
    "a,b, c, d, e = eval(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effff7f-7c3a-4c16-bee0-0bb6e8c4570a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
